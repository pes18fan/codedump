{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09393990-fe5a-483f-813a-7d0b0512f443",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction via Logistic Regression\n",
    "\n",
    "First we grab the dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74999686-ee2e-4ec0-a4d1-b0154e80b109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Chest pain type</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FBS over 120</th>\n",
       "      <th>EKG results</th>\n",
       "      <th>Max HR</th>\n",
       "      <th>Exercise angina</th>\n",
       "      <th>ST depression</th>\n",
       "      <th>Slope of ST</th>\n",
       "      <th>Number of vessels fluro</th>\n",
       "      <th>Thallium</th>\n",
       "      <th>Heart Disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>322</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Presence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Presence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Absence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>269</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Absence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex  Chest pain type   BP  Cholesterol  FBS over 120  EKG results  \\\n",
       "0   70    1                4  130          322             0            2   \n",
       "1   67    0                3  115          564             0            2   \n",
       "2   57    1                2  124          261             0            0   \n",
       "3   64    1                4  128          263             0            0   \n",
       "4   74    0                2  120          269             0            2   \n",
       "\n",
       "   Max HR  Exercise angina  ST depression  Slope of ST  \\\n",
       "0     109                0            2.4            2   \n",
       "1     160                0            1.6            2   \n",
       "2     141                0            0.3            1   \n",
       "3     105                1            0.2            2   \n",
       "4     121                1            0.2            1   \n",
       "\n",
       "   Number of vessels fluro  Thallium Heart Disease  \n",
       "0                        3         3      Presence  \n",
       "1                        0         7       Absence  \n",
       "2                        0         7      Presence  \n",
       "3                        1         7       Absence  \n",
       "4                        1         3       Absence  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "file_path = \"Heart_Disease_Prediction.csv\"\n",
    "\n",
    "df = kagglehub.dataset_load(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"neurocipher/heartdisease\",\n",
    "  file_path\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605828dc-48dd-4712-8f55-2b6e705d87bd",
   "metadata": {},
   "source": [
    "The dataset consists of information on a number of patients, followed by the \"Heart Disease\" column that indicates whether the patient has or doesn't have heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3ee2de-db78-4eb5-9d1e-84b98168033d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14582390-1ec9-4c8d-ab9a-97e994a58d74",
   "metadata": {},
   "source": [
    "Dataset consists of 270 patients with 14 pieces of information on each. Next we need to ensure there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccd28927-ff36-4184-9b92-8379de1bcd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Chest pain type</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FBS over 120</th>\n",
       "      <th>EKG results</th>\n",
       "      <th>Max HR</th>\n",
       "      <th>Exercise angina</th>\n",
       "      <th>ST depression</th>\n",
       "      <th>Slope of ST</th>\n",
       "      <th>Number of vessels fluro</th>\n",
       "      <th>Thallium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.00000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.433333</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>3.174074</td>\n",
       "      <td>131.344444</td>\n",
       "      <td>249.659259</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>149.677778</td>\n",
       "      <td>0.329630</td>\n",
       "      <td>1.05000</td>\n",
       "      <td>1.585185</td>\n",
       "      <td>0.670370</td>\n",
       "      <td>4.696296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.109067</td>\n",
       "      <td>0.468195</td>\n",
       "      <td>0.950090</td>\n",
       "      <td>17.861608</td>\n",
       "      <td>51.686237</td>\n",
       "      <td>0.355906</td>\n",
       "      <td>0.997891</td>\n",
       "      <td>23.165717</td>\n",
       "      <td>0.470952</td>\n",
       "      <td>1.14521</td>\n",
       "      <td>0.614390</td>\n",
       "      <td>0.943896</td>\n",
       "      <td>1.940659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>153.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.80000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.60000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.20000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age         Sex  Chest pain type          BP  Cholesterol  \\\n",
       "count  270.000000  270.000000       270.000000  270.000000   270.000000   \n",
       "mean    54.433333    0.677778         3.174074  131.344444   249.659259   \n",
       "std      9.109067    0.468195         0.950090   17.861608    51.686237   \n",
       "min     29.000000    0.000000         1.000000   94.000000   126.000000   \n",
       "25%     48.000000    0.000000         3.000000  120.000000   213.000000   \n",
       "50%     55.000000    1.000000         3.000000  130.000000   245.000000   \n",
       "75%     61.000000    1.000000         4.000000  140.000000   280.000000   \n",
       "max     77.000000    1.000000         4.000000  200.000000   564.000000   \n",
       "\n",
       "       FBS over 120  EKG results      Max HR  Exercise angina  ST depression  \\\n",
       "count    270.000000   270.000000  270.000000       270.000000      270.00000   \n",
       "mean       0.148148     1.022222  149.677778         0.329630        1.05000   \n",
       "std        0.355906     0.997891   23.165717         0.470952        1.14521   \n",
       "min        0.000000     0.000000   71.000000         0.000000        0.00000   \n",
       "25%        0.000000     0.000000  133.000000         0.000000        0.00000   \n",
       "50%        0.000000     2.000000  153.500000         0.000000        0.80000   \n",
       "75%        0.000000     2.000000  166.000000         1.000000        1.60000   \n",
       "max        1.000000     2.000000  202.000000         1.000000        6.20000   \n",
       "\n",
       "       Slope of ST  Number of vessels fluro    Thallium  \n",
       "count   270.000000               270.000000  270.000000  \n",
       "mean      1.585185                 0.670370    4.696296  \n",
       "std       0.614390                 0.943896    1.940659  \n",
       "min       1.000000                 0.000000    3.000000  \n",
       "25%       1.000000                 0.000000    3.000000  \n",
       "50%       2.000000                 0.000000    3.000000  \n",
       "75%       2.000000                 1.000000    7.000000  \n",
       "max       3.000000                 3.000000    7.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3189469e-75da-4709-aeaa-c34c0f4d1c7b",
   "metadata": {},
   "source": [
    "Every column has a `count` of 270, and as `count` only counts non-NaN values, there are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e734fa-3f35-4d90-8f86-e6be7d096c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Presence\n",
       "1       Absence\n",
       "2      Presence\n",
       "3       Absence\n",
       "4       Absence\n",
       "         ...   \n",
       "265     Absence\n",
       "266     Absence\n",
       "267     Absence\n",
       "268     Absence\n",
       "269    Presence\n",
       "Name: Heart Disease, Length: 270, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_str = df[\"Heart Disease\"]\n",
    "labels_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24559c5e-57cc-473a-af98-b412f7da32d8",
   "metadata": {},
   "source": [
    "This is the target variable, and while it appears to be binary it is a string rather than a binary number, so we need to convert it to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11576aca-a84e-4eab-bc56-546cc373d5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Heart Disease, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = labels_str.map({'Absence': 0, 'Presence': 1})\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9dee4-be65-4672-834e-6a750c8b1d4c",
   "metadata": {},
   "source": [
    "We now need to ensure \"Presence\" and \"Absence\" were indeed the only possible values for \"Heart Disease\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e30e3b3-0c43-48ff-8f57-100c682202b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb7d5fe-270d-4bc3-88d5-be939d76a3e6",
   "metadata": {},
   "source": [
    "This confirms `labels` is binary, so we can move on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff00d4-0ad0-4e33-8f64-d74b1c464eb8",
   "metadata": {},
   "source": [
    "## Logistic Regression with One Input Feature\n",
    "\n",
    "For this purpose we will choose the feature \"Cholesterol\". This is because abnormal levels of cholesterol is known to be a fairly well known indicator of cardiovascular issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9a6326-9ac7-41cd-bb24-b30b582eeaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    322\n",
       "1    564\n",
       "2    261\n",
       "3    263\n",
       "4    269\n",
       "Name: Cholesterol, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df[\"Cholesterol\"]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e750e0a-6112-483b-99e6-050508b2f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994eae64-645a-4606-9ba7-06332ba4dc6d",
   "metadata": {},
   "source": [
    "The features and labels have been chosen. Now, we move to picking the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7228789-8a06-4969-a594-6e7344d4d42b",
   "metadata": {},
   "source": [
    "For this purpose, **Logistic Regression** is a good choice. This is because logistic regression is specifically designed for classifying and fitting data into specific containers by transformation using a logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4124556f-0eeb-4f74-abc2-fd7e689e0c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0605c482-11e9-4d7d-a05b-5a93556f8f2a",
   "metadata": {},
   "source": [
    "One important step that should be performed now is feature scaling. Scaling is necessary to tame outliers, because those outliers would otherwise dominate the decision-making of the model and increase inaccuracy dramatically. For this purpose we will use the `StandardScaler` provided by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41c262e8-4082-4d72-9eb5-a64ea2a2c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52beb5a7-9421-4d4d-b5ef-834b3ea8a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6891573d-242c-434b-b480-405497661621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cholesterol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.402212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.093004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.219823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.258589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.374890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cholesterol\n",
       "0     1.402212\n",
       "1     6.093004\n",
       "2     0.219823\n",
       "3     0.258589\n",
       "4     0.374890"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_data = pd.DataFrame(scaler.fit_transform(x.values.reshape(-1,1)), columns=['cholesterol'])\n",
    "standardized_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d442ac-3f4d-4961-9cbb-5bc1923d509c",
   "metadata": {},
   "source": [
    "We now split the data such that some of it is used for training and the rest for testing. We will be using 20% of the data for testing and the rest to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c5804ca-8f68-4d0c-a3af-ddd6c449ca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "923cd1c9-a9e8-4ed2-9a2a-8adbb35d63d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (216, 1)\n",
      "x_test shape: (54, 1)\n",
      "y_train shape: (216,)\n",
      "y_test shape: (54,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(standardized_data, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eacee2f-878b-4fd1-8784-66786af09c92",
   "metadata": {},
   "source": [
    "Now we need to pick a loss function to tell the algorithm how to perform the learning. We will use the log-loss function, which is the default for scikit-learn (so we don't need to explicitly pick it).\n",
    "\n",
    "The log loss function is a function that measures the divergence of the predicted probability with the actual labels. The less the output of this function, the better the model. For a hypothetical perfect model, the log loss = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1eedd22-cda5-417f-9d63-139ee2609240",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=42).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393767b-71a6-45c7-b8da-c08fb91270b6",
   "metadata": {},
   "source": [
    "The model has been trained. We can now see how well it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e0d74a6-609a-492f-a243-2695cfb82683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.score(x_test, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06473ea4-b19a-483d-9a7d-bc7cd89aab76",
   "metadata": {},
   "source": [
    "The score is around 0.611 which indicates the model got 61.1% of its predictions correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc5c9a8a-46dc-4f53-a0a8-5020142f3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88b75303-4347-422c-bf89-4de78cdfec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  5]\n",
      " [16  5]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1b97b-098c-4cd7-b05c-d03c09514863",
   "metadata": {},
   "source": [
    "According to the confusion matrix, we can see that the model got 28 positive diagnoses right and 5 negative diagnoses correct, but had 16 false negatives and 5 false positives.\n",
    "\n",
    "We can find further information by calculating the F1 score, recall, precision and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4a6cc51-133a-4992-bcb4-3c946da44f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean, std\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c539c5fa-bf50-48b0-84f0-2fe930020e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "f1:\t\t 0.3225806451612903\n",
      "recall\t\t 0.23809523809523808\n",
      "precision\t 0.5\n",
      "\n",
      "f1_avg:\t\t 0.5249266862170088\n",
      "recall_avg\t 0.5432900432900433\n",
      "precision_avg\t 0.5681818181818181\n",
      "\n",
      "f1_sd:\t\t 0.2023460410557185\n",
      "recall_sd\t 0.3051948051948052\n",
      "precision_sd\t 0.06818181818181818\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73        33\n",
      "           1       0.50      0.24      0.32        21\n",
      "\n",
      "    accuracy                           0.61        54\n",
      "   macro avg       0.57      0.54      0.52        54\n",
      "weighted avg       0.58      0.61      0.57        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "f1 = f1_score(y_test, pred_labels)\n",
    "recall = recall_score(y_test, pred_labels)\n",
    "precision = precision_score(y_test, pred_labels)\n",
    "\n",
    "f1_avg = mean(f1_score(y_test, pred_labels, average=None))\n",
    "recall_avg = mean(recall_score(y_test, pred_labels, average=None))\n",
    "precision_avg = mean(precision_score(y_test, pred_labels, average=None))\n",
    "\n",
    "f1_sd = std(f1_score(y_test, pred_labels, average=None))\n",
    "recall_sd = std(recall_score(y_test, pred_labels, average=None))\n",
    "precision_sd = std(precision_score(y_test, pred_labels, average=None))\n",
    "\n",
    "print('\\nf1:\\t\\t',f1)\n",
    "print('recall\\t\\t',recall)\n",
    "print('precision\\t',precision)\n",
    "\n",
    "print('\\nf1_avg:\\t\\t',f1_avg)\n",
    "print('recall_avg\\t',recall_avg)\n",
    "print('precision_avg\\t',precision_avg)\n",
    "\n",
    "print('\\nf1_sd:\\t\\t',f1_sd)\n",
    "print('recall_sd\\t',recall_sd)\n",
    "print('precision_sd\\t',precision_sd)\n",
    "\n",
    "print('\\n',classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2611539-67ae-41c9-9884-e939cc963a7f",
   "metadata": {},
   "source": [
    "The precision of 0.5 implies the level of usefulness of the results, which is not particularly high.\n",
    "\n",
    "The recall of 0.24 is especially poor and implies the results are not very complete; however the class of data in the binary value 0 (negatives) have a significantly higher recall of 0.85.\n",
    "\n",
    "We can also use cross-validation to get even more accurate numbers without the risk of overfitting on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76f7142a-d086-4541-a414-f438d848da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "cv_pred_labels = cross_val_predict(model, standardized_data, labels, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a283de4-52ba-4f17-a611-63e43c15a3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\t 0.5407407407407407\n",
      "[[128  22]\n",
      " [102  18]]\n",
      "\n",
      "f1:\t\t 0.225\n",
      "recall\t\t 0.15\n",
      "precision\t 0.45\n",
      "\n",
      "f1_avg:\t\t 0.4493421052631579\n",
      "recall_avg\t 0.5016666666666667\n",
      "precision_avg\t 0.5032608695652174\n",
      "\n",
      "f1_sd:\t\t 0.2243421052631579\n",
      "recall_sd\t 0.3516666666666667\n",
      "precision_sd\t 0.05326086956521739\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.85      0.67       150\n",
      "           1       0.45      0.15      0.23       120\n",
      "\n",
      "    accuracy                           0.54       270\n",
      "   macro avg       0.50      0.50      0.45       270\n",
      "weighted avg       0.51      0.54      0.47       270\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(labels, cv_pred_labels)\n",
    "\n",
    "cm = confusion_matrix(labels, cv_pred_labels)\n",
    "\n",
    "f1 = f1_score(labels, cv_pred_labels)\n",
    "recall = recall_score(labels, cv_pred_labels)\n",
    "precision = precision_score(labels, cv_pred_labels)\n",
    "\n",
    "f1_avg = mean(f1_score(labels, cv_pred_labels, average=None))\n",
    "recall_avg = mean(recall_score(labels, cv_pred_labels, average=None))\n",
    "precision_avg = mean(precision_score(labels, cv_pred_labels, average=None))\n",
    "\n",
    "f1_sd = std(f1_score(labels, cv_pred_labels, average=None))\n",
    "recall_sd = std(recall_score(labels, cv_pred_labels, average=None))\n",
    "precision_sd = std(precision_score(labels, cv_pred_labels, average=None))\n",
    "\n",
    "print('accuracy:\\t', accuracy)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "print('\\nf1:\\t\\t',f1)\n",
    "print('recall\\t\\t',recall)\n",
    "print('precision\\t',precision)\n",
    "\n",
    "print('\\nf1_avg:\\t\\t',f1_avg)\n",
    "print('recall_avg\\t',recall_avg)\n",
    "print('precision_avg\\t',precision_avg)\n",
    "\n",
    "print('\\nf1_sd:\\t\\t',f1_sd)\n",
    "print('recall_sd\\t',recall_sd)\n",
    "print('precision_sd\\t',precision_sd)\n",
    "\n",
    "print('\\n',classification_report(labels, cv_pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf2f7bf-a94d-48c0-b1f5-43111a8565db",
   "metadata": {},
   "source": [
    "This provides a final accuracy of 0.54.\n",
    "\n",
    "Notably, the recall and precision is even lower.\n",
    "\n",
    "Overall, only using one input feature seems to provide poor results. Theoretically, having multiple features fixes this issue, which we shall test next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe4521d-e9cb-40e9-9a2d-321d68874ceb",
   "metadata": {},
   "source": [
    "## Logistic Regression with Multiple Input Features\n",
    "\n",
    "We will now use all the features except for \"Heart Disease\" which is the label, as the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41a5cb6d-9530-4c12-8c39-c9a5d00c02f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BP</th>\n",
       "      <th>Chest pain type</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>EKG results</th>\n",
       "      <th>Exercise angina</th>\n",
       "      <th>FBS over 120</th>\n",
       "      <th>Max HR</th>\n",
       "      <th>Number of vessels fluro</th>\n",
       "      <th>ST depression</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Slope of ST</th>\n",
       "      <th>Thallium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>564</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>269</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age   BP  Chest pain type  Cholesterol  EKG results  Exercise angina  \\\n",
       "0   70  130                4          322            2                0   \n",
       "1   67  115                3          564            2                0   \n",
       "2   57  124                2          261            0                0   \n",
       "3   64  128                4          263            0                1   \n",
       "4   74  120                2          269            2                1   \n",
       "\n",
       "   FBS over 120  Max HR  Number of vessels fluro  ST depression  Sex  \\\n",
       "0             0     109                        3            2.4    1   \n",
       "1             0     160                        0            1.6    0   \n",
       "2             0     141                        0            0.3    1   \n",
       "3             0     105                        1            0.2    1   \n",
       "4             0     121                        1            0.2    0   \n",
       "\n",
       "   Slope of ST  Thallium  \n",
       "0            2         3  \n",
       "1            2         7  \n",
       "2            1         7  \n",
       "3            2         7  \n",
       "4            1         3  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df[df.columns.difference([\"Heart Disease\"])]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b39b20c-1422-4073-82f9-696544471f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c80b1-e182-48e9-9f47-e13d22a02d69",
   "metadata": {},
   "source": [
    "We now follow similar steps as followed in the single feature form to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adff27ff-74bb-4766-8279-74933a726236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>chest pain type</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>ekg results</th>\n",
       "      <th>exercise angina</th>\n",
       "      <th>fbs over 120</th>\n",
       "      <th>max hr</th>\n",
       "      <th>number of vessels fluro</th>\n",
       "      <th>st depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>slope of st</th>\n",
       "      <th>thallium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.712094</td>\n",
       "      <td>-0.075410</td>\n",
       "      <td>0.870928</td>\n",
       "      <td>1.402212</td>\n",
       "      <td>0.981664</td>\n",
       "      <td>-0.701222</td>\n",
       "      <td>-0.417029</td>\n",
       "      <td>-1.759208</td>\n",
       "      <td>2.472682</td>\n",
       "      <td>1.181012</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.676419</td>\n",
       "      <td>-0.875706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.382140</td>\n",
       "      <td>-0.916759</td>\n",
       "      <td>-0.183559</td>\n",
       "      <td>6.093004</td>\n",
       "      <td>0.981664</td>\n",
       "      <td>-0.701222</td>\n",
       "      <td>-0.417029</td>\n",
       "      <td>0.446409</td>\n",
       "      <td>-0.711535</td>\n",
       "      <td>0.481153</td>\n",
       "      <td>-1.450327</td>\n",
       "      <td>0.676419</td>\n",
       "      <td>1.189277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.282294</td>\n",
       "      <td>-0.411950</td>\n",
       "      <td>-1.238045</td>\n",
       "      <td>0.219823</td>\n",
       "      <td>-1.026285</td>\n",
       "      <td>-0.701222</td>\n",
       "      <td>-0.417029</td>\n",
       "      <td>-0.375291</td>\n",
       "      <td>-0.711535</td>\n",
       "      <td>-0.656118</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>-0.954234</td>\n",
       "      <td>1.189277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.052186</td>\n",
       "      <td>-0.187590</td>\n",
       "      <td>0.870928</td>\n",
       "      <td>0.258589</td>\n",
       "      <td>-1.026285</td>\n",
       "      <td>1.426081</td>\n",
       "      <td>-0.417029</td>\n",
       "      <td>-1.932198</td>\n",
       "      <td>0.349871</td>\n",
       "      <td>-0.743600</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.676419</td>\n",
       "      <td>1.189277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.152032</td>\n",
       "      <td>-0.636310</td>\n",
       "      <td>-1.238045</td>\n",
       "      <td>0.374890</td>\n",
       "      <td>0.981664</td>\n",
       "      <td>1.426081</td>\n",
       "      <td>-0.417029</td>\n",
       "      <td>-1.240239</td>\n",
       "      <td>0.349871</td>\n",
       "      <td>-0.743600</td>\n",
       "      <td>-1.450327</td>\n",
       "      <td>-0.954234</td>\n",
       "      <td>-0.875706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age        bp  chest pain type  cholesterol  ekg results  \\\n",
       "0  1.712094 -0.075410         0.870928     1.402212     0.981664   \n",
       "1  1.382140 -0.916759        -0.183559     6.093004     0.981664   \n",
       "2  0.282294 -0.411950        -1.238045     0.219823    -1.026285   \n",
       "3  1.052186 -0.187590         0.870928     0.258589    -1.026285   \n",
       "4  2.152032 -0.636310        -1.238045     0.374890     0.981664   \n",
       "\n",
       "   exercise angina  fbs over 120    max hr  number of vessels fluro  \\\n",
       "0        -0.701222     -0.417029 -1.759208                 2.472682   \n",
       "1        -0.701222     -0.417029  0.446409                -0.711535   \n",
       "2        -0.701222     -0.417029 -0.375291                -0.711535   \n",
       "3         1.426081     -0.417029 -1.932198                 0.349871   \n",
       "4         1.426081     -0.417029 -1.240239                 0.349871   \n",
       "\n",
       "   st depression       sex  slope of st  thallium  \n",
       "0       1.181012  0.689500     0.676419 -0.875706  \n",
       "1       0.481153 -1.450327     0.676419  1.189277  \n",
       "2      -0.656118  0.689500    -0.954234  1.189277  \n",
       "3      -0.743600  0.689500     0.676419  1.189277  \n",
       "4      -0.743600 -1.450327    -0.954234 -0.875706  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardized_data = pd.DataFrame(scaler.fit_transform(x), columns=[\"age\", \"bp\", \"chest pain type\", \"cholesterol\",\n",
    "                                                                   \"ekg results\", \"exercise angina\", \"fbs over 120\",\n",
    "                                                                   \"max hr\", \"number of vessels fluro\", \"st depression\",\n",
    "                                                                   \"sex\", \"slope of st\", \"thallium\"])\n",
    "standardized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "325e0941-1d45-40d3-9b6a-283163d4c26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (216, 13)\n",
      "x_test shape: (54, 13)\n",
      "y_train shape: (216,)\n",
      "y_test shape: (54,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(standardized_data, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c101fe4-a76c-4930-b632-80b8c506295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=42).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ee629e-1212-4af4-ab39-2de441f1a878",
   "metadata": {},
   "source": [
    "The model is now ready. We can now test to see how well this one does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab03390b-ea68-49ef-a99a-32b1b326f286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9074074074074074"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.score(x_test, y_test)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dcbbd1-6ab1-4531-a9f6-e1850343044e",
   "metadata": {},
   "source": [
    "Immediately, we can see that the score has shot up to 0.907 from 0.611, indicating this model is significantly better performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "485c6477-d7be-445d-b41e-1dac72cfcb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f4f0d3c4-77ea-4881-a68f-974d0848d92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31  2]\n",
      " [ 3 18]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, pred_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41a1db9-25bb-4dab-8211-d32a3087c9ed",
   "metadata": {},
   "source": [
    "The confusion matrix tells a similar story; there are very few false positives and false negatives and a lot of correct predictions.\n",
    "\n",
    "Now we prepare the full classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab470c89-946c-4f40-85a2-11a79ed70514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "f1:\t\t 0.8780487804878049\n",
      "recall\t\t 0.8571428571428571\n",
      "precision\t 0.9\n",
      "\n",
      "f1_avg:\t\t 0.9017109574080815\n",
      "recall_avg\t 0.8982683982683983\n",
      "precision_avg\t 0.9058823529411765\n",
      "\n",
      "f1_sd:\t\t 0.023662176920276667\n",
      "recall_sd\t 0.041125541125541176\n",
      "precision_sd\t 0.00588235294117645\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93        33\n",
      "           1       0.90      0.86      0.88        21\n",
      "\n",
      "    accuracy                           0.91        54\n",
      "   macro avg       0.91      0.90      0.90        54\n",
      "weighted avg       0.91      0.91      0.91        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "f1 = f1_score(y_test, pred_labels)\n",
    "recall = recall_score(y_test, pred_labels)\n",
    "precision = precision_score(y_test, pred_labels)\n",
    "\n",
    "f1_avg = mean(f1_score(y_test, pred_labels, average=None))\n",
    "recall_avg = mean(recall_score(y_test, pred_labels, average=None))\n",
    "precision_avg = mean(precision_score(y_test, pred_labels, average=None))\n",
    "\n",
    "f1_sd = std(f1_score(y_test, pred_labels, average=None))\n",
    "recall_sd = std(recall_score(y_test, pred_labels, average=None))\n",
    "precision_sd = std(precision_score(y_test, pred_labels, average=None))\n",
    "\n",
    "print('\\nf1:\\t\\t',f1)\n",
    "print('recall\\t\\t',recall)\n",
    "print('precision\\t',precision)\n",
    "\n",
    "print('\\nf1_avg:\\t\\t',f1_avg)\n",
    "print('recall_avg\\t',recall_avg)\n",
    "print('precision_avg\\t',precision_avg)\n",
    "\n",
    "print('\\nf1_sd:\\t\\t',f1_sd)\n",
    "print('recall_sd\\t',recall_sd)\n",
    "print('precision_sd\\t',precision_sd)\n",
    "\n",
    "print('\\n',classification_report(y_test, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45186d7-f2e6-4e2c-bfd7-b9a1d314159b",
   "metadata": {},
   "source": [
    "The final accuracy here is 0.91, far higher than when using only one input feature.\n",
    "\n",
    "The precision and recall are also significantly higher at 0.9 and 0.857 respectively, indicating that the results are both quite useful and also have a high level of completeness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
